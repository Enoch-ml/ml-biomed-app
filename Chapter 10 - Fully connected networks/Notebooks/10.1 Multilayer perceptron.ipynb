{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/MLP_binary_classifier_cropped.png\" width = \"350\" style=\"float: right;\">\n",
    "\n",
    "# Multilayer perceptron for non-linear classification\n",
    "\n",
    "The flexibility of the neural networks comes from combining many artificial neurons into a single machine learning model organized in multiple layers. Linear layers of neurons with multiple outputs can be stacked one after another resulting in a **multi layer perceptron** model. If we add non-linear activation functions between the layers, we will be able to create flexible non-linear models. Networks consisting of several linear layers are also called **fully connected deep neural networks**. \n",
    "\n",
    "The image on the right illustrates a two-layer network that we will create to build a **non-linear binary classifier**. It has two input features. The first linear layer has two inputs and six outputs. Multiple outputs will give us flexibility to fit a highly non-linear decision boundary. The six outputs of the first layer will become inputs of the second layer, which has only one output. After the first layer, we will have **ReLU** activation, to introduce non-linearity to the network. After the second layer we have **Sigmoid** activation to build a binary classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Non-linear classifier\n",
    "\n",
    "In this exercise we are going to fit a multi-layer perceptron to a simulated dataset with two co-centric circles. Run the cell below to create and display the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "\n",
    "X,y = make_circles(n_samples=500,factor=0.5, noise=0.08)\n",
    "\n",
    "X = torch.from_numpy(X).float()\n",
    "y = torch.from_numpy(y.reshape(-1,1)).float()\n",
    "print('X: ', X.shape)\n",
    "print('y: ', y.shape)\n",
    "\n",
    "def PlotData2(X,y):\n",
    "    y=y.flatten()\n",
    "    plt.plot(X[y==0,0],X[y==0,1],'bo',alpha=0.75,markeredgecolor='k')\n",
    "    plt.plot(X[y==1,0],X[y==1,1],'rd',alpha=0.75,markeredgecolor='k')\n",
    "    plt.axis('equal')\n",
    "    plt.title('Circles', fontsize = 14)\n",
    "    #plt.axis('off')\n",
    "\n",
    "plt.figure(figsize = (5,5))\n",
    "PlotData2(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a slightly different function to plot the classification result, run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotClassification2(net,X,y):\n",
    "\n",
    "    # Create an 1D array of samples for each feature\n",
    "    a = 0.2\n",
    "    x1 = np.linspace(X[:,0].min()-a, X[:,0].max()+a, 1000) \n",
    "    x2 = np.linspace(X[:,1].min()-a, X[:,1].max()+a, 1000).T # note the transpose\n",
    "    # Creates 2D arrays that hold the coordinates in 2D feature space\n",
    "    x1, x2 = np.meshgrid(x1, x2) \n",
    "    # Flatten x1 and x2 to 1D vector and concatenate into a feature matrix\n",
    "    Feature_space = np.c_[x1.ravel(), x2.ravel()] \n",
    "    \n",
    "    # NEW: convert numpy to torch\n",
    "    Feature_space = torch.from_numpy(Feature_space).float()\n",
    "    # NEW: Predict output scores for the whole feature space    \n",
    "    output_scores = net(Feature_space)\n",
    "    # NEW: Threshold output scores\n",
    "    y_pred = (output_scores>0.5).long()\n",
    "    \n",
    "    # Resahpe to 2D\n",
    "    y_pred = y_pred.reshape(x1.shape)\n",
    "    # Plot using contourf\n",
    "    plt.contourf(x1, x2, y_pred, cmap = 'summer')\n",
    "    \n",
    "    # Plot data\n",
    "    PlotData2(X,y)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1:** In the cell below is a working code to fit a single-layer perceptron to the dataset. Run the code. What do you observe? Is the classifier suitable for the dataset?\n",
    "\n",
    "**Answer:** \n",
    "\n",
    "**Task 2:** Modify the network architecture so that it can fit this non-linear dataset. In function `__init__` implement \n",
    "* linear `layer1` with two inputs and 6 outputs\n",
    "* `ReLU` activation\n",
    "* linear `layer2` with 6 inputs and one output\n",
    "* `Sigmoid` activation\n",
    "Then modify the `forward` function accordingly. Run the cell to train and display the multi-layer perceptron classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.layer1 = nn.Linear(2, 1)\n",
    "        #self.relu = nn.ReLU() \n",
    "        #self.layer2 = None\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "def train(net, X, y):\n",
    "    loss_function = nn.BCELoss()\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=0.2, momentum=0.75)\n",
    "    epochs = 500\n",
    "    for i in range(epochs):\n",
    "        optimizer.zero_grad() \n",
    "        prediction = net(X) \n",
    "        loss = loss_function(prediction, y) \n",
    "        loss.backward()       \n",
    "        optimizer.step()   \n",
    "    return net\n",
    "\n",
    "net2 = MLPClassifier()\n",
    "train(net2,X,y)\n",
    "PlotClassification2(net2,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3:** Simulate an additional dataset to create an independent test set. Calculate accuracy on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate test set\n",
    "X_test, y_test = make_circles(n_samples=500,factor=0.5, noise=0.08)\n",
    "\n",
    "# convert to tensors\n",
    "X_test =None\n",
    "y_test = None\n",
    "print('X_test: ', X_test.shape)\n",
    "print('y_test: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probabilities for class 1\n",
    "pred = None\n",
    "\n",
    "# threshold to create labels\n",
    "y_pred_test = None\n",
    "\n",
    "# calculate accuracy\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
